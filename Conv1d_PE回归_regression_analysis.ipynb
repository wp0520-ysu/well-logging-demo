{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv1d PE回归 regression analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3uEr3jTLBJoh81WqTjPJQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunyingjian/AI-in-well-logging/blob/master/Conv1d_PE%E5%9B%9E%E5%BD%92_regression_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gVGf35ZpmS_",
        "outputId": "fcd536d1-cec8-4e6b-c9c2-bf0dbd842605"
      },
      "source": [
        "!git clone https://github.com/sunyingjian/numpy-.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'numpy-'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 415 (delta 3), reused 0 (delta 0), pack-reused 403\u001b[K\n",
            "Receiving objects: 100% (415/415), 202.24 MiB | 34.83 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "Checking out files: 100% (206/206), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehsy9bo4pzgg",
        "outputId": "dad5ec1f-04a2-409d-e6ec-aa3eea65ae1d"
      },
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Feb  1 08:29:05 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEo-5LvTp5P9"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from tensorflow import keras\r\n",
        "%matplotlib inline\r\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "s-ewohcpp7_e",
        "outputId": "61cf71e2-7412-47e8-9339-97ffe93a9a3b"
      },
      "source": [
        "data = pd.read_csv('/content/numpy-/TCN data.csv')\r\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Formation</th>\n",
              "      <th>Depth</th>\n",
              "      <th>GR</th>\n",
              "      <th>ILD_log10</th>\n",
              "      <th>DeltaPHI</th>\n",
              "      <th>PHIND</th>\n",
              "      <th>NM_M</th>\n",
              "      <th>RELPOS</th>\n",
              "      <th>Facies</th>\n",
              "      <th>Well Name</th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.399818</td>\n",
              "      <td>0.298966</td>\n",
              "      <td>0.458149</td>\n",
              "      <td>0.776042</td>\n",
              "      <td>0.219321</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.557385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.400729</td>\n",
              "      <td>0.302738</td>\n",
              "      <td>0.456157</td>\n",
              "      <td>0.888021</td>\n",
              "      <td>0.231865</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978788</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.494046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.401639</td>\n",
              "      <td>0.306417</td>\n",
              "      <td>0.454165</td>\n",
              "      <td>0.903646</td>\n",
              "      <td>0.241224</td>\n",
              "      <td>0</td>\n",
              "      <td>0.956566</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.430707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.402550</td>\n",
              "      <td>0.339247</td>\n",
              "      <td>0.452173</td>\n",
              "      <td>0.880208</td>\n",
              "      <td>0.242479</td>\n",
              "      <td>0</td>\n",
              "      <td>0.935354</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.418039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.403461</td>\n",
              "      <td>0.285601</td>\n",
              "      <td>0.446860</td>\n",
              "      <td>0.869792</td>\n",
              "      <td>0.246049</td>\n",
              "      <td>0</td>\n",
              "      <td>0.914141</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0.405371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3227</th>\n",
              "      <td>3227</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.996357</td>\n",
              "      <td>0.155858</td>\n",
              "      <td>0.646070</td>\n",
              "      <td>0.565833</td>\n",
              "      <td>0.129373</td>\n",
              "      <td>1</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.432860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3228</th>\n",
              "      <td>3228</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.997268</td>\n",
              "      <td>0.145818</td>\n",
              "      <td>0.650055</td>\n",
              "      <td>0.576589</td>\n",
              "      <td>0.144021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.673737</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.398277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3229</th>\n",
              "      <td>3229</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.998179</td>\n",
              "      <td>0.169829</td>\n",
              "      <td>0.657359</td>\n",
              "      <td>0.594401</td>\n",
              "      <td>0.144021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.665657</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.378769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3230</th>\n",
              "      <td>3230</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.999089</td>\n",
              "      <td>0.177978</td>\n",
              "      <td>0.658023</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.138135</td>\n",
              "      <td>1</td>\n",
              "      <td>0.657576</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.373955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3231</th>\n",
              "      <td>3231</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171282</td>\n",
              "      <td>0.661343</td>\n",
              "      <td>0.586172</td>\n",
              "      <td>0.118065</td>\n",
              "      <td>1</td>\n",
              "      <td>0.649495</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.392070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3232 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  Formation     Depth  ...  Facies  Well Name        PE\n",
              "0              0   0.076923  0.399818  ...       3          7  0.557385\n",
              "1              1   0.076923  0.400729  ...       3          7  0.494046\n",
              "2              2   0.076923  0.401639  ...       3          7  0.430707\n",
              "3              3   0.076923  0.402550  ...       3          7  0.418039\n",
              "4              4   0.076923  0.403461  ...       3          7  0.405371\n",
              "...          ...        ...       ...  ...     ...        ...       ...\n",
              "3227        3227   0.923077  0.996357  ...       5          0  0.432860\n",
              "3228        3228   0.923077  0.997268  ...       5          0  0.398277\n",
              "3229        3229   0.923077  0.998179  ...       5          0  0.378769\n",
              "3230        3230   0.923077  0.999089  ...       5          0  0.373955\n",
              "3231        3231   0.923077  1.000000  ...       5          0  0.392070\n",
              "\n",
              "[3232 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfZAd1vvp-xI",
        "outputId": "cd9d471a-be3b-4935-aef5-cd1cf41fbb10"
      },
      "source": [
        "data['Well Name'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    501\n",
              "7    471\n",
              "3    463\n",
              "2    461\n",
              "6    449\n",
              "4    415\n",
              "0    404\n",
              "5     68\n",
              "Name: Well Name, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNGsFtgzqKOq"
      },
      "source": [
        "# 分割数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piS-Xn8yqA5E"
      },
      "source": [
        "test_data = data.loc[data['Well Name']==1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQJmgj5XqMZf"
      },
      "source": [
        "test_data = test_data.drop(columns=['Unnamed: 0','Well Name'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fANtOj4HqOoW"
      },
      "source": [
        "index=data[data['Well Name'].isin([1])].index[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQoyjD4fqQmZ"
      },
      "source": [
        "training_data = data.drop(index = [i for i in range(1381,1882)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JRw9KKLqSf_"
      },
      "source": [
        "train_data = training_data.drop(columns=['Well Name','Unnamed: 0'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYJy1cfsqUhe"
      },
      "source": [
        "train_data =  train_data.reset_index(drop=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFP1NPUUqWie"
      },
      "source": [
        "test_data = test_data.reset_index(drop=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "OvvlqjvGqYq-",
        "outputId": "590e4991-ec98-470e-cfb8-6bb67bf5ada1"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Formation</th>\n",
              "      <th>Depth</th>\n",
              "      <th>GR</th>\n",
              "      <th>ILD_log10</th>\n",
              "      <th>DeltaPHI</th>\n",
              "      <th>PHIND</th>\n",
              "      <th>NM_M</th>\n",
              "      <th>RELPOS</th>\n",
              "      <th>Facies</th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.399818</td>\n",
              "      <td>0.298966</td>\n",
              "      <td>0.458149</td>\n",
              "      <td>0.776042</td>\n",
              "      <td>0.219321</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>0.557385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.400729</td>\n",
              "      <td>0.302738</td>\n",
              "      <td>0.456157</td>\n",
              "      <td>0.888021</td>\n",
              "      <td>0.231865</td>\n",
              "      <td>0</td>\n",
              "      <td>0.978788</td>\n",
              "      <td>3</td>\n",
              "      <td>0.494046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.401639</td>\n",
              "      <td>0.306417</td>\n",
              "      <td>0.454165</td>\n",
              "      <td>0.903646</td>\n",
              "      <td>0.241224</td>\n",
              "      <td>0</td>\n",
              "      <td>0.956566</td>\n",
              "      <td>3</td>\n",
              "      <td>0.430707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.402550</td>\n",
              "      <td>0.339247</td>\n",
              "      <td>0.452173</td>\n",
              "      <td>0.880208</td>\n",
              "      <td>0.242479</td>\n",
              "      <td>0</td>\n",
              "      <td>0.935354</td>\n",
              "      <td>3</td>\n",
              "      <td>0.418039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.403461</td>\n",
              "      <td>0.285601</td>\n",
              "      <td>0.446860</td>\n",
              "      <td>0.869792</td>\n",
              "      <td>0.246049</td>\n",
              "      <td>0</td>\n",
              "      <td>0.914141</td>\n",
              "      <td>3</td>\n",
              "      <td>0.405371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2726</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.996357</td>\n",
              "      <td>0.155858</td>\n",
              "      <td>0.646070</td>\n",
              "      <td>0.565833</td>\n",
              "      <td>0.129373</td>\n",
              "      <td>1</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>5</td>\n",
              "      <td>0.432860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2727</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.997268</td>\n",
              "      <td>0.145818</td>\n",
              "      <td>0.650055</td>\n",
              "      <td>0.576589</td>\n",
              "      <td>0.144021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.673737</td>\n",
              "      <td>5</td>\n",
              "      <td>0.398277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2728</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.998179</td>\n",
              "      <td>0.169829</td>\n",
              "      <td>0.657359</td>\n",
              "      <td>0.594401</td>\n",
              "      <td>0.144021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.665657</td>\n",
              "      <td>5</td>\n",
              "      <td>0.378769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2729</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.999089</td>\n",
              "      <td>0.177978</td>\n",
              "      <td>0.658023</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.138135</td>\n",
              "      <td>1</td>\n",
              "      <td>0.657576</td>\n",
              "      <td>5</td>\n",
              "      <td>0.373955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2730</th>\n",
              "      <td>0.923077</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171282</td>\n",
              "      <td>0.661343</td>\n",
              "      <td>0.586172</td>\n",
              "      <td>0.118065</td>\n",
              "      <td>1</td>\n",
              "      <td>0.649495</td>\n",
              "      <td>5</td>\n",
              "      <td>0.392070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2731 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Formation     Depth        GR  ...    RELPOS  Facies        PE\n",
              "0      0.076923  0.399818  0.298966  ...  1.000000       3  0.557385\n",
              "1      0.076923  0.400729  0.302738  ...  0.978788       3  0.494046\n",
              "2      0.076923  0.401639  0.306417  ...  0.956566       3  0.430707\n",
              "3      0.076923  0.402550  0.339247  ...  0.935354       3  0.418039\n",
              "4      0.076923  0.403461  0.285601  ...  0.914141       3  0.405371\n",
              "...         ...       ...       ...  ...       ...     ...       ...\n",
              "2726   0.923077  0.996357  0.155858  ...  0.681818       5  0.432860\n",
              "2727   0.923077  0.997268  0.145818  ...  0.673737       5  0.398277\n",
              "2728   0.923077  0.998179  0.169829  ...  0.665657       5  0.378769\n",
              "2729   0.923077  0.999089  0.177978  ...  0.657576       5  0.373955\n",
              "2730   0.923077  1.000000  0.171282  ...  0.649495       5  0.392070\n",
              "\n",
              "[2731 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJB60hSdsiCT"
      },
      "source": [
        "#分割数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8VO16eLshl_"
      },
      "source": [
        "training_data = training_data.values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_7-GyVms409"
      },
      "source": [
        "seq_length = 100\r\n",
        "data_ = []\r\n",
        "for i in range(len(train_data)-seq_length):\r\n",
        "  if training_data[i,-2]!=training_data[i+seq_length,-2]:\r\n",
        "    continue\r\n",
        "  data_.append(train_data.iloc[i:i+seq_length])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFJluhk6s8ti"
      },
      "source": [
        "data_ = np.array([df.values for df in data_])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrfGT_uWtJ2s"
      },
      "source": [
        "X = data_[:,:,:9]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6QmNTi9tNNJ"
      },
      "source": [
        "Y = data_[:,:,-1]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auz_nwfytRWW"
      },
      "source": [
        "data_test = []\r\n",
        "for i in range(len(test_data)-seq_length):\r\n",
        "    data_test.append(test_data.iloc[i:i+seq_length])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc0UqHuutTsF"
      },
      "source": [
        "data_test = np.array([df.values for df in data_test])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aut01wEGtV9b"
      },
      "source": [
        "test_x = data_test[:,:,:9]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyrHmnKDtX91"
      },
      "source": [
        "test_y = data_test[:,:,-1]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJATlEkluncU",
        "outputId": "82869b7b-c96e-4325-960c-0bfd58b80fa0"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2063, 100, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A5naiHsrB9y"
      },
      "source": [
        "# 建立Conv1D网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uNr2IGHq--I"
      },
      "source": [
        "input = tf.keras.Input(shape=(100,9))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7FHmnKxre1e"
      },
      "source": [
        "x = tf.keras.layers.Conv1D(32,kernel_size=2,padding='same',activation='relu')(input)\r\n",
        "x = tf.keras.layers.Dense(64,activation='relu',kernel_regularizer='l2')(x)\r\n",
        "x = tf.keras.layers.Dense(1)(x)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QaSq9jor5pM"
      },
      "source": [
        "model = tf.keras.Model(inputs = input,outputs = x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2y5Ia-ot1gb",
        "outputId": "1f0b86c3-c706-46ee-b234-5354462dd4ca"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 100, 9)]          0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 100, 32)           608       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100, 64)           2112      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100, 1)            65        \n",
            "=================================================================\n",
            "Total params: 2,785\n",
            "Trainable params: 2,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ77FJmst9Bl"
      },
      "source": [
        "#学习率衰减\r\n",
        "learning_rate=0.01\r\n",
        "\r\n",
        "Lr_change=tf.keras.callbacks.ReduceLROnPlateau('val_mae',patience = 20, factor = 0.5, min_lr=0.0001)\r\n",
        "#保存准确率最好的模型\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "filepath=\"best_weight.h5\"\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True,mode='min')\r\n",
        "Adam=tf.keras.optimizers.Adam(learning_rate=learning_rate)\r\n",
        "model.compile(optimizer=Adam,loss='mse',metrics=['mae'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqpaWRiJuSry",
        "outputId": "561972a0-c3d2-4646-8263-70235501fbc0"
      },
      "source": [
        "history=model.fit( X,Y,batch_size=128,\r\n",
        "         epochs=100, \r\n",
        "         callbacks=[Lr_change,checkpoint],\r\n",
        "         validation_data=(test_x,test_y))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 8s 30ms/step - loss: 0.4801 - mae: 0.3210 - val_loss: 0.1151 - val_mae: 0.0641\n",
            "\n",
            "Epoch 00001: val_mae improved from inf to 0.06408, saving model to best_weight.h5\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.1025 - mae: 0.0859 - val_loss: 0.0679 - val_mae: 0.0653\n",
            "\n",
            "Epoch 00002: val_mae did not improve from 0.06408\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0627 - mae: 0.0602 - val_loss: 0.0470 - val_mae: 0.0584\n",
            "\n",
            "Epoch 00003: val_mae improved from 0.06408 to 0.05843, saving model to best_weight.h5\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0450 - mae: 0.0573 - val_loss: 0.0356 - val_mae: 0.0525\n",
            "\n",
            "Epoch 00004: val_mae improved from 0.05843 to 0.05249, saving model to best_weight.h5\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0354 - mae: 0.0567 - val_loss: 0.0283 - val_mae: 0.0491\n",
            "\n",
            "Epoch 00005: val_mae improved from 0.05249 to 0.04913, saving model to best_weight.h5\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0287 - mae: 0.0549 - val_loss: 0.0231 - val_mae: 0.0485\n",
            "\n",
            "Epoch 00006: val_mae improved from 0.04913 to 0.04849, saving model to best_weight.h5\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0239 - mae: 0.0544 - val_loss: 0.0190 - val_mae: 0.0458\n",
            "\n",
            "Epoch 00007: val_mae improved from 0.04849 to 0.04577, saving model to best_weight.h5\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 0.0533 - val_loss: 0.0160 - val_mae: 0.0449\n",
            "\n",
            "Epoch 00008: val_mae improved from 0.04577 to 0.04487, saving model to best_weight.h5\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0531 - val_loss: 0.0134 - val_mae: 0.0436\n",
            "\n",
            "Epoch 00009: val_mae improved from 0.04487 to 0.04362, saving model to best_weight.h5\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0150 - mae: 0.0524 - val_loss: 0.0116 - val_mae: 0.0430\n",
            "\n",
            "Epoch 00010: val_mae improved from 0.04362 to 0.04299, saving model to best_weight.h5\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0524 - val_loss: 0.0100 - val_mae: 0.0436\n",
            "\n",
            "Epoch 00011: val_mae did not improve from 0.04299\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0522 - val_loss: 0.0084 - val_mae: 0.0385\n",
            "\n",
            "Epoch 00012: val_mae improved from 0.04299 to 0.03851, saving model to best_weight.h5\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0513 - val_loss: 0.0076 - val_mae: 0.0379\n",
            "\n",
            "Epoch 00013: val_mae improved from 0.03851 to 0.03788, saving model to best_weight.h5\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.0513 - val_loss: 0.0070 - val_mae: 0.0390\n",
            "\n",
            "Epoch 00014: val_mae did not improve from 0.03788\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0514 - val_loss: 0.0061 - val_mae: 0.0383\n",
            "\n",
            "Epoch 00015: val_mae did not improve from 0.03788\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0501 - val_loss: 0.0055 - val_mae: 0.0369\n",
            "\n",
            "Epoch 00016: val_mae improved from 0.03788 to 0.03690, saving model to best_weight.h5\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0500 - val_loss: 0.0055 - val_mae: 0.0382\n",
            "\n",
            "Epoch 00017: val_mae did not improve from 0.03690\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0505 - val_loss: 0.0046 - val_mae: 0.0380\n",
            "\n",
            "Epoch 00018: val_mae did not improve from 0.03690\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0498 - val_loss: 0.0041 - val_mae: 0.0360\n",
            "\n",
            "Epoch 00019: val_mae improved from 0.03690 to 0.03604, saving model to best_weight.h5\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0499 - val_loss: 0.0043 - val_mae: 0.0359\n",
            "\n",
            "Epoch 00020: val_mae improved from 0.03604 to 0.03585, saving model to best_weight.h5\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0500 - val_loss: 0.0038 - val_mae: 0.0353\n",
            "\n",
            "Epoch 00021: val_mae improved from 0.03585 to 0.03526, saving model to best_weight.h5\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0497 - val_loss: 0.0038 - val_mae: 0.0360\n",
            "\n",
            "Epoch 00022: val_mae did not improve from 0.03526\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0493 - val_loss: 0.0032 - val_mae: 0.0331\n",
            "\n",
            "Epoch 00023: val_mae improved from 0.03526 to 0.03307, saving model to best_weight.h5\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0496 - val_loss: 0.0040 - val_mae: 0.0384\n",
            "\n",
            "Epoch 00024: val_mae did not improve from 0.03307\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0503 - val_loss: 0.0035 - val_mae: 0.0378\n",
            "\n",
            "Epoch 00025: val_mae did not improve from 0.03307\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0494 - val_loss: 0.0035 - val_mae: 0.0375\n",
            "\n",
            "Epoch 00026: val_mae did not improve from 0.03307\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0509 - val_loss: 0.0029 - val_mae: 0.0347\n",
            "\n",
            "Epoch 00027: val_mae did not improve from 0.03307\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0501 - val_loss: 0.0031 - val_mae: 0.0351\n",
            "\n",
            "Epoch 00028: val_mae did not improve from 0.03307\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0490 - val_loss: 0.0047 - val_mae: 0.0454\n",
            "\n",
            "Epoch 00029: val_mae did not improve from 0.03307\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0521 - val_loss: 0.0030 - val_mae: 0.0351\n",
            "\n",
            "Epoch 00030: val_mae did not improve from 0.03307\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0496 - val_loss: 0.0029 - val_mae: 0.0360\n",
            "\n",
            "Epoch 00031: val_mae did not improve from 0.03307\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0498 - val_loss: 0.0037 - val_mae: 0.0401\n",
            "\n",
            "Epoch 00032: val_mae did not improve from 0.03307\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0502 - val_loss: 0.0034 - val_mae: 0.0383\n",
            "\n",
            "Epoch 00033: val_mae did not improve from 0.03307\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0494 - val_loss: 0.0026 - val_mae: 0.0348\n",
            "\n",
            "Epoch 00034: val_mae did not improve from 0.03307\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0491 - val_loss: 0.0025 - val_mae: 0.0331\n",
            "\n",
            "Epoch 00035: val_mae did not improve from 0.03307\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0497 - val_loss: 0.0036 - val_mae: 0.0394\n",
            "\n",
            "Epoch 00036: val_mae did not improve from 0.03307\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0499 - val_loss: 0.0026 - val_mae: 0.0343\n",
            "\n",
            "Epoch 00037: val_mae did not improve from 0.03307\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0496 - val_loss: 0.0034 - val_mae: 0.0384\n",
            "\n",
            "Epoch 00038: val_mae did not improve from 0.03307\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0498 - val_loss: 0.0026 - val_mae: 0.0340\n",
            "\n",
            "Epoch 00039: val_mae did not improve from 0.03307\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0487 - val_loss: 0.0035 - val_mae: 0.0392\n",
            "\n",
            "Epoch 00040: val_mae did not improve from 0.03307\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0499 - val_loss: 0.0030 - val_mae: 0.0368\n",
            "\n",
            "Epoch 00041: val_mae did not improve from 0.03307\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0501 - val_loss: 0.0024 - val_mae: 0.0337\n",
            "\n",
            "Epoch 00042: val_mae did not improve from 0.03307\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0494 - val_loss: 0.0023 - val_mae: 0.0320\n",
            "\n",
            "Epoch 00043: val_mae improved from 0.03307 to 0.03205, saving model to best_weight.h5\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0499 - val_loss: 0.0037 - val_mae: 0.0416\n",
            "\n",
            "Epoch 00044: val_mae did not improve from 0.03205\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0501 - val_loss: 0.0031 - val_mae: 0.0377\n",
            "\n",
            "Epoch 00045: val_mae did not improve from 0.03205\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0495 - val_loss: 0.0046 - val_mae: 0.0472\n",
            "\n",
            "Epoch 00046: val_mae did not improve from 0.03205\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0511 - val_loss: 0.0030 - val_mae: 0.0364\n",
            "\n",
            "Epoch 00047: val_mae did not improve from 0.03205\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0499 - val_loss: 0.0029 - val_mae: 0.0359\n",
            "\n",
            "Epoch 00048: val_mae did not improve from 0.03205\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0494 - val_loss: 0.0027 - val_mae: 0.0348\n",
            "\n",
            "Epoch 00049: val_mae did not improve from 0.03205\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0492 - val_loss: 0.0027 - val_mae: 0.0349\n",
            "\n",
            "Epoch 00050: val_mae did not improve from 0.03205\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 0.0024 - val_mae: 0.0322\n",
            "\n",
            "Epoch 00051: val_mae did not improve from 0.03205\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0489 - val_loss: 0.0026 - val_mae: 0.0337\n",
            "\n",
            "Epoch 00052: val_mae did not improve from 0.03205\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 0.0030 - val_mae: 0.0364\n",
            "\n",
            "Epoch 00053: val_mae did not improve from 0.03205\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 0.0025 - val_mae: 0.0359\n",
            "\n",
            "Epoch 00054: val_mae did not improve from 0.03205\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0496 - val_loss: 0.0027 - val_mae: 0.0349\n",
            "\n",
            "Epoch 00055: val_mae did not improve from 0.03205\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0491 - val_loss: 0.0048 - val_mae: 0.0479\n",
            "\n",
            "Epoch 00056: val_mae did not improve from 0.03205\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0521 - val_loss: 0.0033 - val_mae: 0.0389\n",
            "\n",
            "Epoch 00057: val_mae did not improve from 0.03205\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 0.0028 - val_mae: 0.0353\n",
            "\n",
            "Epoch 00058: val_mae did not improve from 0.03205\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 0.0026 - val_mae: 0.0348\n",
            "\n",
            "Epoch 00059: val_mae did not improve from 0.03205\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0497 - val_loss: 0.0023 - val_mae: 0.0324\n",
            "\n",
            "Epoch 00060: val_mae did not improve from 0.03205\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0488 - val_loss: 0.0022 - val_mae: 0.0318\n",
            "\n",
            "Epoch 00061: val_mae improved from 0.03205 to 0.03182, saving model to best_weight.h5\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0500 - val_loss: 0.0023 - val_mae: 0.0326\n",
            "\n",
            "Epoch 00062: val_mae did not improve from 0.03182\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0493 - val_loss: 0.0034 - val_mae: 0.0392\n",
            "\n",
            "Epoch 00063: val_mae did not improve from 0.03182\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0500 - val_loss: 0.0031 - val_mae: 0.0369\n",
            "\n",
            "Epoch 00064: val_mae did not improve from 0.03182\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 0.0025 - val_mae: 0.0329\n",
            "\n",
            "Epoch 00065: val_mae did not improve from 0.03182\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0480 - val_loss: 0.0026 - val_mae: 0.0339\n",
            "\n",
            "Epoch 00066: val_mae did not improve from 0.03182\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0481 - val_loss: 0.0026 - val_mae: 0.0338\n",
            "\n",
            "Epoch 00067: val_mae did not improve from 0.03182\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0486 - val_loss: 0.0030 - val_mae: 0.0368\n",
            "\n",
            "Epoch 00068: val_mae did not improve from 0.03182\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0490 - val_loss: 0.0027 - val_mae: 0.0348\n",
            "\n",
            "Epoch 00069: val_mae did not improve from 0.03182\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0481 - val_loss: 0.0022 - val_mae: 0.0321\n",
            "\n",
            "Epoch 00070: val_mae did not improve from 0.03182\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0438\n",
            "\n",
            "Epoch 00071: val_mae did not improve from 0.03182\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0505 - val_loss: 0.0026 - val_mae: 0.0333\n",
            "\n",
            "Epoch 00072: val_mae did not improve from 0.03182\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0481 - val_loss: 0.0029 - val_mae: 0.0359\n",
            "\n",
            "Epoch 00073: val_mae did not improve from 0.03182\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0485 - val_loss: 0.0036 - val_mae: 0.0412\n",
            "\n",
            "Epoch 00074: val_mae did not improve from 0.03182\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0499 - val_loss: 0.0022 - val_mae: 0.0313\n",
            "\n",
            "Epoch 00075: val_mae improved from 0.03182 to 0.03128, saving model to best_weight.h5\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0501 - val_loss: 0.0021 - val_mae: 0.0296\n",
            "\n",
            "Epoch 00076: val_mae improved from 0.03128 to 0.02959, saving model to best_weight.h5\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0492 - val_loss: 0.0021 - val_mae: 0.0312\n",
            "\n",
            "Epoch 00077: val_mae did not improve from 0.02959\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0507 - val_loss: 0.0023 - val_mae: 0.0325\n",
            "\n",
            "Epoch 00078: val_mae did not improve from 0.02959\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0491 - val_loss: 0.0030 - val_mae: 0.0362\n",
            "\n",
            "Epoch 00079: val_mae did not improve from 0.02959\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 0.0024 - val_mae: 0.0315\n",
            "\n",
            "Epoch 00080: val_mae did not improve from 0.02959\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0482 - val_loss: 0.0031 - val_mae: 0.0376\n",
            "\n",
            "Epoch 00081: val_mae did not improve from 0.02959\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0443\n",
            "\n",
            "Epoch 00082: val_mae did not improve from 0.02959\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0496 - val_loss: 0.0033 - val_mae: 0.0388\n",
            "\n",
            "Epoch 00083: val_mae did not improve from 0.02959\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0492 - val_loss: 0.0043 - val_mae: 0.0468\n",
            "\n",
            "Epoch 00084: val_mae did not improve from 0.02959\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0528 - val_loss: 0.0053 - val_mae: 0.0553\n",
            "\n",
            "Epoch 00085: val_mae did not improve from 0.02959\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0525 - val_loss: 0.0021 - val_mae: 0.0293\n",
            "\n",
            "Epoch 00086: val_mae improved from 0.02959 to 0.02927, saving model to best_weight.h5\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0500 - val_loss: 0.0045 - val_mae: 0.0497\n",
            "\n",
            "Epoch 00087: val_mae did not improve from 0.02927\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0501 - val_loss: 0.0023 - val_mae: 0.0307\n",
            "\n",
            "Epoch 00088: val_mae did not improve from 0.02927\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0487 - val_loss: 0.0058 - val_mae: 0.0579\n",
            "\n",
            "Epoch 00089: val_mae did not improve from 0.02927\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0534 - val_loss: 0.0021 - val_mae: 0.0296\n",
            "\n",
            "Epoch 00090: val_mae did not improve from 0.02927\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0481 - val_loss: 0.0029 - val_mae: 0.0351\n",
            "\n",
            "Epoch 00091: val_mae did not improve from 0.02927\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 0.0021 - val_mae: 0.0297\n",
            "\n",
            "Epoch 00092: val_mae did not improve from 0.02927\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0506 - val_loss: 0.0028 - val_mae: 0.0355\n",
            "\n",
            "Epoch 00093: val_mae did not improve from 0.02927\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0497 - val_loss: 0.0035 - val_mae: 0.0420\n",
            "\n",
            "Epoch 00094: val_mae did not improve from 0.02927\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0487 - val_loss: 0.0024 - val_mae: 0.0312\n",
            "\n",
            "Epoch 00095: val_mae did not improve from 0.02927\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0480 - val_loss: 0.0023 - val_mae: 0.0308\n",
            "\n",
            "Epoch 00096: val_mae did not improve from 0.02927\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 0.0023 - val_mae: 0.0304\n",
            "\n",
            "Epoch 00097: val_mae did not improve from 0.02927\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0479 - val_loss: 0.0032 - val_mae: 0.0380\n",
            "\n",
            "Epoch 00098: val_mae did not improve from 0.02927\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0493 - val_loss: 0.0026 - val_mae: 0.0329\n",
            "\n",
            "Epoch 00099: val_mae did not improve from 0.02927\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0482 - val_loss: 0.0028 - val_mae: 0.0347\n",
            "\n",
            "Epoch 00100: val_mae did not improve from 0.02927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTVFQnJMuXH4",
        "outputId": "893caa89-5ced-4997-d441-632bb04c63c0"
      },
      "source": [
        "import sklearn\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn import linear_model\r\n",
        "import statsmodels.api as sm\r\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzxgH-Rtth4h"
      },
      "source": [
        "test_true_y = test_data['PE'].values"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VSYWEtxvhSZ"
      },
      "source": [
        "def help(model,test_x,test_true_y):\r\n",
        "  y_pred = model.predict(test_x)\r\n",
        "  y_pred1 = y_pred[1,:50,:]\r\n",
        "  y_pred_2 = y_pred[:,50,:]\r\n",
        "  y_pred_3 = y_pred[-1,50:,:]\r\n",
        "  y_pred_true = np.append(y_pred1,y_pred_2)\r\n",
        "  y_pred_true = np.append(y_pred_true,y_pred_3)\r\n",
        "  print(f'MAE={metrics.mean_absolute_error(test_true_y,y_pred_true)}')\r\n",
        "  print(f'可决系数R2:{r2_score(test_true_y,y_pred_true)}')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X72L72WKvjFz",
        "outputId": "fbe40c60-b7f3-487c-ac8d-8b55dd0a03eb"
      },
      "source": [
        "help(model,test_x,test_true_y)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE=0.03524917238417473\n",
            "可决系数R2:0.6444033510463404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx0T3yTwvlNC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}